{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Gaussian Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skeleton definition\n",
    "NUI_SKELETON_POSITION_COUNT = 20\n",
    "\n",
    "NONE = -1\n",
    "HIP_CENTER = 0\n",
    "SPINE = 1\n",
    "SHOULDER_CENTER = 2\n",
    "HEAD = 3\n",
    "SHOULDER_LEFT = 4\n",
    "ELBOW_LEFT = 5\n",
    "WRIST_LEFT = 6\n",
    "HAND_LEFT = 7\n",
    "SHOULDER_RIGHT = 8\n",
    "ELBOW_RIGHT = 9\n",
    "WRIST_RIGHT = 10\n",
    "HAND_RIGHT = 11\n",
    "HIP_LEFT = 12\n",
    "KNEE_LEFT = 13\n",
    "ANKLE_LEFT = 14\n",
    "FOOT_LEFT = 15\n",
    "HIP_RIGHT = 16\n",
    "KNEE_RIGHT = 17\n",
    "ANKLE_RIGHT = 18\n",
    "FOOT_RIGHT = 19\n",
    "\n",
    "nui_skeleton_names = ( \\\n",
    "    'HIP_CENTER', 'SPINE', 'SHOULDER_CENTER', 'HEAD', \\\n",
    "    'SHOULDER_LEFT', 'ELBOW_LEFT', 'WRIST_LEFT', 'HAND_LEFT', \\\n",
    "    'SHOULDER_RIGHT', 'ELBOW_RIGHT', 'WRIST_RIGHT', 'HAND_RIGHT', \\\n",
    "    'HIP_LEFT', 'KNEE_LEFT', 'ANKLE_LEFT', 'FOOT_LEFT', \\\n",
    "    'HIP_RIGHT', 'KNEE_RIGHT', 'ANKLE_RIGHT', 'FOOT_RIGHT' )\n",
    "\n",
    "nui_skeleton_conn = ( \\\n",
    "    NONE, \\\n",
    "    HIP_CENTER, \\\n",
    "    SPINE, \\\n",
    "    SHOULDER_CENTER, \\\n",
    "    # Left arm \n",
    "    SHOULDER_CENTER, \\\n",
    "    SHOULDER_LEFT,  \\\n",
    "    ELBOW_LEFT,  \\\n",
    "    WRIST_LEFT,  \\\n",
    "    # Right arm \n",
    "    SHOULDER_CENTER,  \\\n",
    "    SHOULDER_RIGHT,  \\\n",
    "    ELBOW_RIGHT,  \\\n",
    "    WRIST_RIGHT,  \\\n",
    "    # Left leg \n",
    "    HIP_CENTER,  \\\n",
    "    HIP_LEFT,  \\\n",
    "    KNEE_LEFT,  \\\n",
    "    ANKLE_LEFT,  \\\n",
    "    # Right leg \n",
    "    HIP_CENTER,  \\\n",
    "    HIP_RIGHT,  \\\n",
    "    KNEE_RIGHT,  \\\n",
    "    ANKLE_RIGHT,  \\\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file=None):\n",
    "    \"\"\"\n",
    "      Returns the data, the labels and the person id for each action\n",
    "    \"\"\"\n",
    "    import scipy.io\n",
    "    \n",
    "    if file is None:\n",
    "        ex = scipy.io.loadmat('data/data.mat')\n",
    "    else:\n",
    "        ex = scipy.io.loadmat(file)\n",
    "        \n",
    "    return ex['data'],ex['labels'],ex['individuals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_normpdf(x, mu, sigma):\n",
    "    \"\"\"\n",
    "      Computes the natural logarithm of the normal probability density function\n",
    "      \n",
    "    \"\"\"\n",
    "    #log_prob\n",
    "    return -np.log(sigma*np.sqrt(2*np.pi))-np.power((x-mu),2) / (2*np.power(sigma,2))\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_logprobs(log_probs):\n",
    "    \"\"\"\n",
    "       Returns the log prob normalizes so that when exponenciated\n",
    "       it adds up to 1 (Useful to normalizes logprobs)\n",
    "    \"\"\"\n",
    "    mm = np.max(log_probs)\n",
    "    return log_probs - mm - np.log(np.sum(np.exp(log_probs - mm)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_gaussian(X, W=None):\n",
    "    \"\"\"\n",
    "      Compute the mean and variance of X, \n",
    "      You can ignore W for the moment\n",
    "    \"\"\"\n",
    "    mean = np.mean(X)\n",
    "    sigma = np.std(X,axis = 0, ddof = 1)\n",
    "    return (mean, sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_cov(x,y,w):\n",
    "    \"\"\"\n",
    "      Useful function for fit_linear_gaussian\n",
    "    \"\"\"\n",
    "    return np.mean(x*y) - np.mean(x)*np.mean(y)\n",
    "#     return np.sum(w*x*y)/np.sum(w)-np.sum(w*x)*np.sum(w*y)/np.sum(w)/np.sum(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_linear_gaussian(Y,X,W = None):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      Y: vector of size D with the observations for the variable\n",
    "      X: matrix DxV with the observations for the parent variables\n",
    "                 of X. V is the number of parent variables\n",
    "      W: vector of size D with the weights of the instances (ignore for the moment)\n",
    "      \n",
    "    Outout:\n",
    "       The betas and sigma\n",
    "    \"\"\"\n",
    "    if W is None:\n",
    "        W = np.ones(Y.shape[0])\n",
    "    (D,V) = np.array(X).shape\n",
    "    # A construction\n",
    "    A = np.zeros((V+1,V+1))\n",
    "    A[0,0] = 1\n",
    "    \n",
    "    for i in range(1,(V+1)):\n",
    "        A[0,i] = np.mean(X[:,i-1],dtype=np.float64)\n",
    "    A[1:V+1,0] = np.transpose(A[0,1:V+1])\n",
    "    \n",
    "    for i in range(1,V+1):\n",
    "        for j in range(1,V+1):\n",
    "            A[i,j] = np.mean(np.multiply(X[:,i-1],X[:,j-1]),dtype=np.float64)\n",
    "    \n",
    "    # B construction \n",
    "    B = np.zeros( (V+1, 1) )\n",
    "    B[0] = np.mean(Y,dtype=np.float64)\n",
    "    for k in range(1,V+1):\n",
    "          #Eval\n",
    "#         B[k] = np.mean(np.multiply(Y[:,0], X[:,k-1]),dtype=np.float64)\n",
    "        B[k] = np.mean(np.multiply(Y, X[:,k-1]),dtype=np.float64)\n",
    "\n",
    "    # Compute betas\n",
    "    betas = np.linalg.solve(A, B)\n",
    "\n",
    "    # Compute sigma\n",
    "    b = np.delete(betas, 0)\n",
    "    cov_y = my_cov(Y,Y,W)\n",
    "    sigma = 0\n",
    "    for i in range(0,V):\n",
    "        for j in range(0,V):\n",
    "            cov = my_cov(X[:,i], X[:,j], W)\n",
    "            sigma = sigma + b[i] * b[j] * cov\n",
    "    sigma = np.sqrt(cov_y - sigma ) + 0.01\n",
    "\n",
    "    return (betas,sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_model(dataset, labels, G=None):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "     dataset: The data as it is loaded from load_data\n",
    "     labels:  The labels as loaded from load_data\n",
    "     Graph:   (optional) If None, this def should compute the naive \n",
    "           bayes model. If it contains a skel description (pe \n",
    "           nui_skeleton_conn, as obtained from skel_model) then it should\n",
    "           compute the model using the Linear Gausian Model\n",
    "\n",
    "    Output: the model\n",
    "     a (tentative) structure for the output model is:\n",
    "       model.connectivity: the input Graph variable should be stored here \n",
    "                           for later use.\n",
    "       model.class_priors: containing a vector with the prior estimations\n",
    "                           for each class\n",
    "       model.jointparts[i] contains the estimated parameters for the i-th joint\n",
    "\n",
    "          For joints that only depend on the class model.jointparts(i) has:\n",
    "            model.jointparts(i).means: a matrix of 3 x #classes with the\n",
    "                   estimated means for each of the x,y,z variables of the \n",
    "                   i-th joint and for each class.\n",
    "            model.jointparts(i).sigma: a matrix of 3 x #classes with the\n",
    "                   estimated stadar deviations for each of the x,y,z \n",
    "                   variables of the i-th joint and for each class.\n",
    "\n",
    "          For joints that follow a gausian linear model model.jointparts(i) has:\n",
    "            model.jointparts(i).betas: a matrix of 12 x #classes with the\n",
    "                   estimated betas for each x,y,z variables (12 in total) \n",
    "                   of the i-th joint and for each class label.\n",
    "            model.jointparts(i).sigma: as above\n",
    "\n",
    "    \"\"\"\n",
    "    # dataset attribute sizes \n",
    "    total_joints = dataset.shape[0]\n",
    "    total_vars = dataset.shape[1] # (x,y,z)\n",
    "    total_instances = dataset.shape[2]\n",
    "    total_classes = 4\n",
    "    classes = np.unique(labels)\n",
    "\n",
    "    model = lambda: None\n",
    "    model.connectivity = None\n",
    "    model.jointparts = [None]*total_joints\n",
    "    model.class_priors = np.zeros(total_classes)\n",
    "    # calculating priors\n",
    "    class_bin = np.array([1,2,3,4,8])\n",
    "    class_hist = np.histogram(labels,class_bin)[0]\n",
    "\n",
    "    for i in range(0, total_classes):\n",
    "        if class_hist[i] != 0:\n",
    "            model.class_priors[i] = class_hist[i] / labels.shape[0]\n",
    "    # Init joint parts        \n",
    "    for i in range(0, total_joints):\n",
    "        model.jointparts[i] = lambda: None\n",
    "        model.jointparts[i].means = np.zeros((total_vars,total_classes))\n",
    "        model.jointparts[i].betas = np.zeros((total_classes*total_vars,total_classes))\n",
    "        model.jointparts[i].sigma = np.zeros((total_vars,total_classes))\n",
    "\n",
    "    # NAIVE BAYES\n",
    "    if G is None:\n",
    "        for class_idx in range(0,total_classes):\n",
    "            for i in range(0, total_joints):\n",
    "                for j in range(0, total_vars):\n",
    "                    ( model.jointparts[i].means[j,class_idx], model.jointparts[i].sigma[j,class_idx] ) = fit_gaussian(dataset[i,j,np.transpose(np.where(labels==classes[class_idx])[0])]) #np.transpose(np.where(labels==classes(class_idx)))\n",
    "#                     model.jointparts[i].sigma[j,class_idx] = np.sqrt( model.jointparts[i].sigma[j,class_idx] )\n",
    "    # LINEAR GAUSSIAN MODEL\n",
    "    else:\n",
    "        model.connectivity = G\n",
    "        \n",
    "        for class_idx in range(0,total_classes):\n",
    "            for i in range(0, total_joints):\n",
    "                for j in range(0, total_vars):\n",
    "                    if i == 0:\n",
    "                        ( model.jointparts[i].means[j,class_idx], model.jointparts[i].sigma[j,class_idx] ) = fit_gaussian(dataset[i,j,np.transpose(np.where(labels==classes[class_idx])[0])]) #np.transpose(np.where(labels==classes(class_idx)))\n",
    "                    else:\n",
    "                        parent_joint = G[i]\n",
    "                        X = np.squeeze( dataset[parent_joint,:, np.transpose(np.where(labels==classes[class_idx])[0])] )\n",
    "                        Y = np.squeeze( dataset[i,j,np.transpose(np.where(labels==classes[class_idx])[0])] ) #np.transpose(np.where(labels==classes(class_idx)))\n",
    "                        (betas, sigma) = fit_linear_gaussian(Y,X)\n",
    "                        model.jointparts[i].betas[j*total_classes:j*total_classes+total_vars+1,class_idx] = betas.ravel()\n",
    "                        model.jointparts[i].sigma[j,class_idx] = sigma\n",
    "        \n",
    "                        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_instances(instances, model):\n",
    "    \"\"\"    \n",
    "    Input\n",
    "       instance: a 20x3x#instances matrix defining body positions of\n",
    "                 instances\n",
    "       model: as the output of learn_model\n",
    "\n",
    "    Output\n",
    "       probs: a matrix of #instances x #classes with the probability of each\n",
    "              instance of belonging to each of the classes\n",
    "\n",
    "    Important: to avoid underflow numerical issues this computations should\n",
    "               be performed in log space\n",
    "    \"\"\"\n",
    "\n",
    "    total_instances = instances.shape[2]\n",
    "    total_classes = 4\n",
    "\n",
    "    probs = np.zeros( (total_instances, total_classes) )\n",
    "    \n",
    "    for i in range(0,total_instances):\n",
    "        probs[i,:] = compute_logprobs(instances[:,:,i], model)\n",
    "    # Exponentiate to convert the log range into [0,1]\n",
    "    return np.exp(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_logprobs(example, model):\n",
    "    \"\"\"\n",
    "\n",
    "       Input\n",
    "           instance: a 20x3 matrix defining body positions of one instance\n",
    "           model: as given by learn_model\n",
    "\n",
    "       Output\n",
    "           l: a vector of len #classes containing the loglikelihhod of the \n",
    "              instance\n",
    "\n",
    "    \"\"\"\n",
    "    total_joints = example.shape[0]\n",
    "    total_vars = example.shape[1] # (x,y,z)\n",
    "    total_classes = 4\n",
    "    \n",
    "    l = np.zeros((total_classes))\n",
    "    \n",
    "    for class_idx in range(0,total_classes):\n",
    "            for i in range(0, total_joints):\n",
    "                for j in range(0, total_vars):\n",
    "                    mean = 0\n",
    "                    if i == 0 or model.connectivity is None:\n",
    "                        mean =  model.jointparts[i].means[j,class_idx]\n",
    "                    else:\n",
    "                        parent = model.connectivity[i]\n",
    "                        for k in range(0,total_vars+1):\n",
    "                            acc = model.jointparts[i].betas[(j)*(total_classes)+k,class_idx]\n",
    "                            if k != 0:\n",
    "                                acc = acc * example[parent,k-1]\n",
    "                            mean = mean + acc\n",
    "                    sigma = model.jointparts[i].sigma[j][class_idx]\n",
    "                    log_prob = log_normpdf(example[i,j], mean, sigma)\n",
    "                    l[class_idx] = l[class_idx] + log_prob \n",
    "                    l[class_idx] + np.log(model.class_priors[class_idx])\n",
    "    return normalize_logprobs(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fit_test(file=None):\n",
    "    \"\"\"\n",
    "      Returns the data, the labels and the person id for each action\n",
    "    \"\"\"\n",
    "    import scipy.io\n",
    "    \n",
    "    if file is None:\n",
    "        ex = scipy.io.loadmat('data/ejemplolineargaussian.mat')\n",
    "    else:\n",
    "        ex = scipy.io.loadmat(file)\n",
    "    ex = ex['ejemplo']    \n",
    "    return ex['inputY'],ex['inputX'],ex['outputBetas'], ex['outputSigma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_validation(file=None):\n",
    "    \"\"\"\n",
    "      Returns the data, the labels and the person id for each action\n",
    "    \"\"\"\n",
    "    import scipy.io\n",
    "    \n",
    "    if file is None:\n",
    "        ex = scipy.io.loadmat('data/validation_data.mat')\n",
    "    else:\n",
    "        ex = scipy.io.loadmat(file)\n",
    "    return ex['data_small'], ex['labels_small'], ex['train_indexes'],ex['test_indexes']#,ex['outputBetas'], ex['outputSigma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Accuracy:  0.9572127139364304\n",
      "LGM Accuracy:  0.9963325183374083\n",
      "#Naive Bayes\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "         both arms lifted       1.00      0.94      0.97       192\n",
      "      right arms extended       1.00      1.00      1.00       200\n",
      "                   crouch       0.95      0.94      0.94       216\n",
      "arms extended to one side       0.89      0.96      0.92       210\n",
      "\n",
      "              avg / total       0.96      0.96      0.96       818\n",
      "\n",
      "#LGM\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "         both arms lifted       1.00      0.99      0.99       192\n",
      "      right arms extended       1.00      1.00      1.00       200\n",
      "                   crouch       1.00      1.00      1.00       216\n",
      "arms extended to one side       0.99      1.00      0.99       210\n",
      "\n",
      "              avg / total       1.00      1.00      1.00       818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MAIN LAUNCHER\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# # TESTING fit_linear_gaussian\n",
    "# (Y, X, opBetas, opSigma) = load_fit_test()\n",
    "# Y_squeeze = Y[0][0] #np.squeeze(Y)\n",
    "# X_squeeze = X[0][0] #np.squeeze(X)\n",
    "\n",
    "# # flat_Y = [val for sublist in Y for val in sublist]\n",
    "\n",
    "# (betas, sigma) = fit_linear_gaussian(Y_squeeze, X_squeeze)\n",
    "# # print(\"X: \", X_squeeze)\n",
    "# print(\"Betas: \", betas)\n",
    "# print(\"Sigma: \", sigma)\n",
    "\n",
    "# LOAD DATASET\n",
    "(data, labels, individuals) = load_dataset('data/data.mat')\n",
    "\n",
    "# (data, labels, indices_train, indices_test) = load_validation()\n",
    "\n",
    "#CROSS VALIDATION\n",
    "for i in range(1,11):\n",
    "    # Divide data into train and test \n",
    "    data_train, data_test, labels_train, labels_test = train_test_split(np.transpose(data), labels, test_size=0.4)\n",
    "    scores_NB = []\n",
    "    scores_LGM = []\n",
    "    data_trian = np.transpose(data_train)\n",
    "    data_test = np.transpose(data_test)\n",
    "\n",
    "#     indices = np.random.permutation(labels.shape[0])\n",
    "#     train_max_index = int(np.round(individuals.shape[0]*.6))\n",
    "#     indices_train = indices[0:train_max_index]\n",
    "#     indices_test = indices[train_max_index:individuals.shape[0]]\n",
    "\n",
    "    # Training \n",
    "    model_NB = learn_model(data_trian, labels_train)\n",
    "    model_LGM = learn_model(data_trian, labels_train, nui_skeleton_conn)\n",
    "\n",
    "    # Classification\n",
    "    prob_NB = classify_instances(data_test, model_NB)\n",
    "    prob_LGM = classify_instances(data_test, model_LGM)\n",
    "\n",
    "    lbls_NB = np.argmax(prob_NB, axis=1)+1\n",
    "    lbls_NB[lbls_NB == 4] = 8\n",
    "    acc_nb = np.mean(labels_test.ravel()==lbls_NB)\n",
    "    \n",
    "    lbls_LGM = np.argmax(prob_LGM, axis=1)+1\n",
    "    lbls_LGM[lbls_LGM == 4] = 8\n",
    "    acc_lgm = np.mean(labels_test.ravel()==lbls_LGM)\n",
    "    scores_NB.append(acc_nb)\n",
    "    scores_LGM.append(acc_lgm)\n",
    "    \n",
    "print(\"NB Accuracy: \" , np.mean(scores_NB))\n",
    "print(\"LGM Accuracy: \", np.mean(scores_LGM))\n",
    "\n",
    "target_names = ['both arms lifted', 'right arms extended', 'crouch', 'arms extended to one side']\n",
    "print(\"#Naive Bayes\")\n",
    "print(classification_report(labels_test.ravel(), lbls_NB, target_names=target_names))\n",
    "print(\"#LGM\")\n",
    "print(classification_report(labels_test.ravel(), lbls_LGM, target_names=target_names))\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 4  Fold\n",
      "NB Accuracy:  0.9301003189438348\n",
      "LGM Accuracy:  0.9583297117522314\n",
      "# 5  Fold\n",
      "NB Accuracy:  0.9346293505129637\n",
      "LGM Accuracy:  0.9704095363602028\n",
      "# 6  Fold\n",
      "NB Accuracy:  0.9485146024953671\n",
      "LGM Accuracy:  0.9937065176258261\n",
      "# 7  Fold\n",
      "NB Accuracy:  0.9495787355900885\n",
      "LGM Accuracy:  0.9918027210884353\n",
      "# 8  Fold\n",
      "NB Accuracy:  0.949001378186295\n",
      "LGM Accuracy:  0.9909379931309756\n",
      "# 10  Fold\n",
      "NB Accuracy:  0.950031644897034\n",
      "LGM Accuracy:  0.9923043400878836\n",
      "# 20  Fold\n",
      "NB Accuracy:  0.9499981507196378\n",
      "LGM Accuracy:  0.9933379844670167\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## KFOLD\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# LOAD DATASET\n",
    "(data, labels, individuals) = load_dataset('data/data.mat')\n",
    "scores_fold_NB = []\n",
    "scores_fold_LGM = []\n",
    "for i in [4,5,6,7,8,10,20]:\n",
    "    kf = StratifiedKFold(n_splits=i)\n",
    "    scores_NB = []\n",
    "    scores_LGM = []\n",
    "    print(\"#\",i,\" Fold\")\n",
    "\n",
    "    # Divide data into train and test \n",
    "    for train_index, test_index in kf.split(np.transpose(data),individuals):\n",
    "        data_train = data[:,:,train_index]\n",
    "        data_test = data[:,:,test_index]\n",
    "        labels_train = labels[train_index]\n",
    "        labels_test = labels[test_index]\n",
    "        model_NB = learn_model(data_train, labels_train)\n",
    "        model_LGM = learn_model(data_train, labels_train, nui_skeleton_conn)\n",
    "\n",
    "        # Classification\n",
    "        prob_NB = classify_instances(data_test, model_NB)\n",
    "        prob_LGM = classify_instances(data_test, model_LGM)\n",
    "\n",
    "        lbls_NB = np.argmax(prob_NB, axis=1)+1\n",
    "        lbls_NB[lbls_NB == 4] = 8\n",
    "        acc_nb = accuracy_score(labels_test.ravel(),lbls_NB)\n",
    "        scores_NB.append(acc_nb)\n",
    "\n",
    "        lbls_LGM = np.argmax(prob_LGM, axis=1)+1\n",
    "        lbls_LGM[lbls_LGM == 4] = 8\n",
    "        acc_lgm = accuracy_score(labels_test.ravel(),lbls_LGM)\n",
    "        scores_LGM.append(acc_lgm)\n",
    "    print(\"NB Accuracy: \" , np.mean(scores_NB))\n",
    "    print(\"LGM Accuracy: \", np.mean(scores_LGM))\n",
    "    scores_fold_NB.append(np.mean(scores_NB))\n",
    "    scores_fold_LGM.append(np.mean(scores_LGM))\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "ax.plot([4,5,6,7,8,10,20], scores_fold_NB, label='Naive Bayes')\n",
    "ax.plot([4,5,6,7,8,10,20], scores_fold_LGM, label='Linear Gaussian')\n",
    "ax.plot([4,5,6,7,8,10,20], scores_fold_NB, 'bo')\n",
    "ax.plot([4,5,6,7,8,10,20], scores_fold_LGM, 'ro')\n",
    "plt.ylabel='Accuracy'\n",
    "plt.xlabel='k-Folds'\n",
    "plt.title('Model Comparison: K-Folds')\n",
    "plt.grid(True)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 20  Fold\n",
      "NB Accuracy:  0.9511002444987775\n",
      "LGM Accuracy:  0.9955990220048899\n",
      "#Naive Bayes\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "         both arms lifted       1.00      1.00      1.00         1\n",
      "\n",
      "              avg / total       1.00      1.00      1.00         1\n",
      "\n",
      "#LGM\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "         both arms lifted       1.00      1.00      1.00         1\n",
      "\n",
      "              avg / total       1.00      1.00      1.00         1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kalex/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 1, does not match size of target_names, 4\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    }
   ],
   "source": [
    "## LOO\n",
    "from sklearn.model_selection import LeavePOut\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# LOAD DATASET\n",
    "(data, labels, individuals) = load_dataset('data/data.mat')\n",
    "\n",
    "scores_fold_NB = []\n",
    "scores_fold_LGM = []\n",
    "\n",
    "lpo = LeavePOut(p=1)    \n",
    "scores_NB = []\n",
    "scores_LGM = []\n",
    "print(\"#\",i,\" Fold\")\n",
    "\n",
    "# Divide data into train and test \n",
    "for train_index, test_index in lpo.split(np.transpose(data)):\n",
    "    data_train = data[:,:,train_index]\n",
    "    data_test = data[:,:,test_index]\n",
    "    labels_train = labels[train_index]\n",
    "    labels_test = labels[test_index]\n",
    "    model_NB = learn_model(data_train, labels_train)\n",
    "    model_LGM = learn_model(data_train, labels_train, nui_skeleton_conn)\n",
    "\n",
    "    # Classification\n",
    "    prob_NB = classify_instances(data_test, model_NB)\n",
    "    prob_LGM = classify_instances(data_test, model_LGM)\n",
    "\n",
    "    lbls_NB = np.argmax(prob_NB, axis=1)+1\n",
    "    lbls_NB[lbls_NB == 4] = 8\n",
    "    acc_nb = accuracy_score(labels_test.ravel(),lbls_NB)\n",
    "    scores_NB.append(acc_nb)\n",
    "\n",
    "    lbls_LGM = np.argmax(prob_LGM, axis=1)+1\n",
    "    lbls_LGM[lbls_LGM == 4] = 8\n",
    "    acc_lgm = accuracy_score(labels_test.ravel(),lbls_LGM)\n",
    "    scores_LGM.append(acc_lgm)\n",
    "    \n",
    "print(\"NB Accuracy: \" , np.mean(scores_NB))\n",
    "print(\"LGM Accuracy: \", np.mean(scores_LGM))\n",
    "# target_names = ['both arms lifted', 'right arms extended', 'crouch', 'arms extended to one side']\n",
    "# print(\"#Naive Bayes\")\n",
    "# print(classification_report(labels_test.ravel(), lbls_NB, target_names=target_names))\n",
    "# print(\"#LGM\")\n",
    "# print(classification_report(labels_test.ravel(), lbls_LGM, target_names=target_names))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
